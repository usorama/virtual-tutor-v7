#!/usr/bin/env node

/**
 * PC-005 Live Voice Session Test
 * Tests actual LiveKit connection with Python agent running
 */

const { chromium } = require('playwright');
const fs = require('fs');
const path = require('path');

const TEST_URL = 'http://localhost:3006';
const SCREENSHOTS_DIR = '.playwright-mcp';

async function testLiveVoiceSession() {
  // Ensure screenshots directory exists
  if (!fs.existsSync(SCREENSHOTS_DIR)) {
    fs.mkdirSync(SCREENSHOTS_DIR, { recursive: true });
  }

  const browser = await chromium.launch({
    headless: false,
    slowMo: 1000
  });

  const context = await browser.newContext({
    permissions: ['microphone'] // Grant microphone permission
  });
  const page = await context.newPage();

  // Collect console messages
  const consoleMessages = [];
  page.on('console', msg => {
    const text = `[${msg.type()}] ${msg.text()}`;
    consoleMessages.push(text);
    console.log(text);
  });

  // Monitor network requests
  const apiRequests = [];
  page.on('request', request => {
    if (request.url().includes('/api/')) {
      const endpoint = request.url().replace(TEST_URL, '');
      console.log(`[API Request] ${request.method()} ${endpoint}`);
      apiRequests.push({
        url: request.url(),
        method: request.method(),
        endpoint: endpoint
      });
    }
  });

  page.on('response', response => {
    if (response.url().includes('/api/')) {
      const req = apiRequests.find(r => r.url === response.url() && !r.status);
      if (req) {
        req.status = response.status();
        console.log(`[API Response] ${req.endpoint} - ${req.status}`);
      }
    }
  });

  try {
    console.log('\n=== PC-005 LIVE Voice Session Test ===\n');
    console.log('Python Agent Status: RUNNING ‚úÖ');
    console.log('LiveKit URL: wss://ai-tutor-prototype-ny9l58vd.livekit.cloud');
    console.log('Test starting...\n');

    // Step 1: Navigate and login
    console.log('1. Navigating to login page...');
    await page.goto(`${TEST_URL}/login`);
    await page.waitForLoadState('networkidle');

    // Login
    console.log('2. Logging in...');
    await page.fill('input[type="email"]', 'test@example.com');
    await page.fill('input[type="password"]', 'TestPassword123!');
    await page.click('button:has-text("Sign In")');

    // Wait for classroom
    try {
      await page.waitForURL('**/classroom', { timeout: 10000 });
      console.log('   ‚úÖ Logged in and at classroom');
    } catch {
      console.log('   ‚ö†Ô∏è Navigation issue, continuing...');
    }

    await page.waitForTimeout(2000);

    // Step 3: Click Start Voice Session
    console.log('3. Starting voice session...');
    const voiceButton = page.locator('button:has-text("Start Voice Session"), button:has-text("Start Session")').first();
    if (await voiceButton.isVisible()) {
      await voiceButton.click();
      console.log('   ‚úÖ Clicked voice session button');

      // Wait for modal
      await page.waitForTimeout(2000);

      // Step 4: Click Start Learning Session in modal
      console.log('4. Looking for Start Learning Session button in modal...');
      const startLearningButton = page.locator('button:has-text("Start Learning Session")').first();

      if (await startLearningButton.isVisible()) {
        console.log('   ‚úÖ Found Start Learning Session button');

        // Click to start actual session
        await startLearningButton.click();
        console.log('   ‚úÖ Clicked Start Learning Session');

        // Wait for LiveKit connection
        console.log('5. Waiting for LiveKit connection and teacher greeting...');
        await page.waitForTimeout(5000);

        // Take screenshot of active session
        await page.screenshot({
          path: path.join(SCREENSHOTS_DIR, 'live-voice-session-active.png'),
          fullPage: true
        });

        // Check for transcription display
        console.log('6. Checking for transcription display...');
        const transcriptSelectors = [
          '.chat-messages',
          '.transcription-display',
          '[data-testid="transcript"]',
          '.message-container',
          '[class*="transcript"]',
          '[class*="message"]'
        ];

        let transcriptFound = false;
        for (const selector of transcriptSelectors) {
          const elements = await page.locator(selector).all();
          if (elements.length > 0) {
            console.log(`   ‚úÖ Found transcript element: ${selector}`);
            transcriptFound = true;

            // Try to get text content
            try {
              const text = await page.locator(selector).first().textContent();
              if (text && text.trim()) {
                console.log(`   üìù Transcript content: "${text.substring(0, 100)}..."`);
              }
            } catch {}
          }
        }

        if (!transcriptFound) {
          console.log('   ‚ö†Ô∏è No transcript elements found yet');
        }

        // Wait longer for teacher audio/greeting
        console.log('7. Monitoring for teacher audio and transcripts...');
        await page.waitForTimeout(10000);

        // Take another screenshot
        await page.screenshot({
          path: path.join(SCREENSHOTS_DIR, 'live-voice-session-after-wait.png'),
          fullPage: true
        });

        // Check again for transcripts
        for (const selector of transcriptSelectors) {
          try {
            const text = await page.locator(selector).first().textContent();
            if (text && text.trim()) {
              console.log(`   üìù Latest transcript: "${text}"`);
              break;
            }
          } catch {}
        }

        // Step 8: Test ending session
        console.log('8. Testing session end...');
        const endButton = page.locator('button:has-text("End"), button:has-text("Stop"), button:has-text("Leave")').first();

        if (await endButton.isVisible()) {
          console.log('   Found end session button');
          await endButton.click();
          console.log('   ‚úÖ Clicked end session');
          await page.waitForTimeout(2000);

          // Check for errors after ending
          const errors = consoleMessages.filter(m => m.includes('[error]') || m.includes('[ERROR]'));
          if (errors.length === 0) {
            console.log('   ‚úÖ Session ended cleanly (no errors)');
          } else {
            console.log('   ‚ö†Ô∏è Errors detected after ending:', errors);
          }
        } else {
          console.log('   ‚ö†Ô∏è No end session button found');
        }
      } else {
        console.log('   ‚ö†Ô∏è Start Learning Session button not found');
      }
    } else {
      console.log('   ‚ö†Ô∏è Voice session button not visible');
    }

    // Final report
    console.log('\n=== LIVE Test Results ===\n');

    // Check API calls
    console.log('API Calls Made:');
    const relevantEndpoints = [
      '/api/livekit/token',
      '/api/session/start',
      '/api/transcription',
      '/api/session/metrics'
    ];

    relevantEndpoints.forEach(endpoint => {
      const calls = apiRequests.filter(r => r.endpoint && r.endpoint.includes(endpoint));
      if (calls.length > 0) {
        console.log(`  ‚úÖ ${endpoint}: ${calls.length} call(s) - Status: ${calls.map(c => c.status || 'pending').join(', ')}`);
      } else {
        console.log(`  ‚ö†Ô∏è ${endpoint}: No calls made`);
      }
    });

    console.log('\n=== Teacher Audio & Transcripts ===');
    console.log('Note: Teacher audio requires:');
    console.log('  1. LiveKit token generated ‚úÖ');
    console.log('  2. Python agent connected ‚úÖ');
    console.log('  3. Gemini Live API key configured ‚úÖ');
    console.log('  4. WebRTC connection established (check screenshots)');

    console.log('\nScreenshots saved:');
    console.log('  - live-voice-session-active.png');
    console.log('  - live-voice-session-after-wait.png');

  } catch (error) {
    console.error('Test failed:', error);
    await page.screenshot({
      path: path.join(SCREENSHOTS_DIR, 'live-voice-session-error.png'),
      fullPage: true
    });
  } finally {
    console.log('\nTest complete. Browser will close in 5 seconds...');
    await page.waitForTimeout(5000);
    await browser.close();
  }
}

// Run the test
testLiveVoiceSession().catch(console.error);